{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab694380",
   "metadata": {},
   "source": [
    "04. 텍스트 분류 실습 - 뉴스 그룹 분류\n",
    "- 사이킷런 예제 데이터\n",
    "- 텍스트 피처 벡터화\n",
    "- 희소 행렬 형태\n",
    "- 희소 행렬 분류에 효과적인 알고리즘 : 로지스틱 회귀, SVM, 나이브 베이즈 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106cd007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news_data = fetch_20newsgroups(subset='all', random_state=156)\n",
    "print(news_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa51b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print('target 클래스의 값과 분포도 \\n', pd.Series(news_data.target).value_counts().sort_index())\n",
    "print('target 클래스의 이름들 \\n', news_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0bfc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 데이터 구성\n",
    "print(news_data.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e473ffe9",
   "metadata": {},
   "source": [
    "- 내용을 제외한 다른 정보 제거\n",
    "- 제목, 소속, 이메일 주소 등 헤더와 푸터 정보들은 target 클래스 값과 유사한 데이터를 가지고 있는 경우가 많아 웬만한 ML 알고리즘을 적용해도 높은 예측 성능을 나타냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363f9547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# subset='train'으로 학습용 데이터만 추출, remove=('headers','footers','quotes')로 내용만 추출\n",
    "train_news = fetch_20newsgroups(subset='train', remove=('headers','footers','quotes'), random_state=156)\n",
    "\n",
    "X_train = train_news.data\n",
    "y_train = train_news.target\n",
    "\n",
    "# subset='test'으로 학습용 데이터만 추출, remove=('headers','footers','quotes')로 내용만 추출\n",
    "test_news = fetch_20newsgroups(subset='test', remove=('headers','footers','quotes'), random_state=156)\n",
    "\n",
    "X_test = test_news.data\n",
    "y_test = test_news.target\n",
    "\n",
    "print('학습 데이터 크기 {0}, 테스트 데이터 크기 {1}'.format(len(train_news.data), len(test_news.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25099a88",
   "metadata": {},
   "source": [
    "- 피처 벡터화 변환과 머신러닝 모델 학습/예측/평가\n",
    "테스트 데이터에서 CountVectorizer 적용시 반드시 학습 데이터를 이용해 fit()이 수행된 CountVectorizer 객체를 이용해 테스트 데이터를 변환해야함          \n",
    "학습시 설정된 피처 개수와 테스트 데이터를 변환한 피처 개수가 같아지도록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45a5dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Count Vectorization으로 피처 벡터화 변환 수행\n",
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(X_train)\n",
    "X_train_cnt_vect = cnt_vect.transform(X_train)\n",
    "\n",
    "# 학습 데이터로 fit()된 CountFectorizer를 이용해 테스트 데이터를 피처 벡터화 변환 수행\n",
    "X_test_cnt_vect = cnt_vect.transform(X_test)\n",
    "\n",
    "print('학습 데이터 테스트의 CountVectorizer Shape:', X_train_cnt_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccfa0e3",
   "metadata": {},
   "source": [
    "101631개의 피처-단어가 생성됨       \n",
    "로지스틱 회귀를 적용해 뉴스그룹 분류 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) Count 기반 예측\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# RogisticRegression을 이용해 학습/예측/평가 수행\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_cnt_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_cnt_vect)\n",
    "print('CountVectorized Logistic Regression의 예측 정확도는 {0:3f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c376658",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) TF-IDF 기반 예측\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF 벡터화를 적용해 학습 데이터 세트와 테스트 데이터 세트 변환\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidt_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidt_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "# RogisticRegression을 이용해 학습/예측/평가 수행\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidt_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidt_vect)\n",
    "print('TF-IDF Logistic Regression의 예측 정확도는 {0:3f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c69621",
   "metadata": {},
   "source": [
    "TF-IDF가 단순 카운트 기반보다 훨씬 높은 예측 정확도 제공     \n",
    "텍스트 분석에서 머신러닝 모델의 성능을 향상시키는 중요한 2가지 방법     \n",
    "최적의 ML 알고리즘 선택    \n",
    "최상의 피처 전처리 수행    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac11a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words 필터링을 추가하고 ngram을 기본 (1,1)에서 (1,2)로 변경해 피처 벡터화 적용\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300)\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidt_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidt_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidt_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidt_vect)\n",
    "print('TF-IDF Logistic Regression의 예측 정확도는 {0:3f}'.format(accuracy_score(y_test, pred)))\n",
    "TF-IDF Logistic Regression의 예측 정확도는 0.692246\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 최적 C값 도출 튜닝 수행. CV는 3폴드 세트로 설정\n",
    "params = { 'C':[0.01, 0.1, 1, 5, 10]}\n",
    "grid_cv_lr = GridSearchCV(lr_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_cv_lr.fit(X_train_tfidt_vect, y_train)\n",
    "print('Logistic Regression best C parameter :', grid_cv_lr.best_params_)\n",
    "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
    "Logistic Regression best C parameter : {'C': 10}\n",
    "# 최적 C값으로 학습된 grid_cv로 예측 및 정확도 평가\n",
    "pred = grid_cv_lr.predict(X_test_tfidt_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression의 예측 정확도는 {0:3f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf4ae1",
   "metadata": {},
   "source": [
    "### 사이킷런 파이프라인(Pipeline) 사용 및 GridSearchCV와의 결합\n",
    "Pipeline 클래스를 이용해 피처 벡터화와 ML 알고리즘 학습/예측을 위한 코드 작성 한번에 진행\n",
    "데이터의 전처리와 머신러닝 학습 과정을 통일된 API 기반에서 처리할 수 있어 더 직관적인 ML 모델 코드 생성 가능\n",
    "대용량 데이터의 피처 벡터화 결과를 별도 데이터로 저장하지 않고 스트림 기반에서 바로 머신러닝 알고리즘 데이터로 입력 가능해 수행 시간 절약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fed1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# TfidVectorizer 객체를 tfid_vect로, LogisticRegression 객체를 lr_clf로 생성하는 Pipeline 생성\n",
    "pipeline=Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300)),\n",
    "    ('lr_clf', LogisticRegression(C=10))\n",
    "])\n",
    "\n",
    "# 별도의 TfidVectorizer 객체의 fit(), transform()과 LogisticRegression의 fit(), predict()가 필요없음\n",
    "# pipeline의 fit과 predict()만으로 한꺼번에 피처 벡터화와 ML 학습/예측이 가능\n",
    "pipeline.fit(X_train, y_train)\n",
    "pred = pipeline.predict(X_test)\n",
    "print('Pipeline을 통한 Logistic Regression의 예측 정확도는 {0:3f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e391ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline=Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english')),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Pipeline에 기술된 각각의 객체 변수에 언더바(__) 2개를 연달아 붙여 GridSearchCV에 사용될 파라미터/하이퍼파라미터 이름과 값을 설정\n",
    "params = {'tfidf_vect__ngram_range':[(1,1),(1,2),(1,3)],\n",
    "         'tfidf_vect__max_df': [100,300,700],\n",
    "         'lr_clf__C':[1,5,10]}\n",
    "\n",
    "# GridSearchCV의 생성자에 Estimator가 아닌 Pipeline 객체 입력\n",
    "grid_cv_pipe = GridSearchCV(pipeline, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_cv_pipe.fit(X_train, y_train)\n",
    "print(grid_cv_pipe.best_params_, grid_cv_pipe.best_score_)\n",
    "\n",
    "pred = grid_cv_pipe.predict(X_test)\n",
    "print('Pipeline을 통한 Logistic Regression의 예측 정확도는 {0:.3f}.format(accuracy_score(y_test,pred))')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03423b8",
   "metadata": {},
   "source": [
    "Pipeline을 통한 Logistic Regression의 예측 정확도는 0.701009\n",
    "Pipeline 기반에서 하이퍼파라미터 튜닝을 GridSearchCV 방식으로 진행 가능\n",
    "피처 벡터화를 위한 파라미터와 ML 알고리즘의 하이퍼 파라미터 한번에 최적화 가능\n",
    "하이퍼파라미터명이 객체 변수명과 결합되어 제공됨 : 개별 객체명과 파라미터/하이퍼파라미터명을 결합해 key값으로 할당"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
